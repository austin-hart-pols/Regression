---
title: "REGRESSION ANALYSIS"
subtitle: "OLS and confounding bias"
author: "Austin Hart"
institute: "American University"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, rladies, rladies-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  message=FALSE, warning=FALSE, eval = TRUE, 
  echo = FALSE, cache = TRUE,
  fig.align = 'center', dev='svg'
)
```


```{r results='hide'}
library(tidyverse)
library(kableExtra)
library(stargazer)

#load("anes2012 workshop.rdata")
load("DCPS testing.RData")
```

# Topics covered

- Reviewing linear regression

- Regression and confounding bias

- Multiple regression to the rescue

- EC quiz


---
class: inverse, middle, right

# LINEAR RELATIONSHIPS
### and basics of a line

---
# Linear regression overview

- Assessing the relationship between:
  - continuous outcome variable (Y)
  - continuous exposure variable (X)

- OLS regression and line of best fit
  - OLS line minimizes squared error
  - Represents mean of $Y$ conditional on $X$

- Key findings (typically)
  - Slope coefficient as expected change in $\bar{Y}$ for unit-increase in $X$
  - Statistical significance of slope
  
  

---
# Visualizing the line of best fit

```{r, fig.width=5, fig.height=4, dpi=250}
# Scatter w/OLS fit (numeric X, numeric Y)
  # Store OLS estimates
    est = lm(ProfLang ~ ProfMath, data = dcps)
  # Plot  
    plot(ProfLang ~ ProfMath, data = dcps) # scatter
      abline(est) # add linear fit
```


---
# Population Regression Function

> What is the impact of variable $X$ on outcome $Y$ in the population?
>
> Assume $Y$ is a linear function of $X$
$$
Y_i = \beta_0 + \beta_1 X_i + e_i
$$

- Parameters of the line
  - Intercept $\beta_0 = E(Y|X=0)$
  - Slope $\beta_1 = E(\Delta Y | \Delta X)$

- The error term $e_i$
  - vertical distance between point and line $Y_i - (\beta_0 + \beta_1 X_i)$
  - the variation in $Y$ not explained by $X$


---
# Sample Regression Function

> Given the observed data in the sample, estimate the PRF as follows: 
>
$$
Y_i = b_0 + b_1 X_i + e_i
$$

- Parameters of the line
  - Intercept $b_0 = E(Y|X=0)$
  - Slope $b_1 = E(\Delta Y | \Delta X)$

- The error term $e_i$
  - vertical distance between point and line $Y_i - (b_0 + b_1 X_i)$
  - variation in $Y$ not explained by X


---
# Interpreting estimates

Given estimates from the sample data:
$$
Y_i = b_0 + b_1X
$$

- Slope coefficient: the expected value of $Y$ increases/decreases by $b_1$ for every one-unit increase in $X$.

- Intercept: the mean of $Y$ when $X=0$ is $b_0$.

---
# Hypothesis testing
### Sample to population

- SRF: $b_0 + b_1 X_i$
  - estimate of PRF, $\beta_0 + \beta_1 X_i$
  - $b_1$ unbiased estimator of $\beta_1$
  - Uncertainty remains about $\beta_1$

- Set hypotheses
  - $H_A: ~ \beta_1 \neq 0$
  - $H_0: ~ \beta_1 = 0$  
  
- Calculate $t$
  - $t=\frac{b_1}{se(b_1)}$
  - For 5% significance, reject $H_0$ if $t>t_{\alpha=0.05}$, typically about 1.96.


---
class: inverse, middle, right

# REGRESSION IN R


---
# Commands

```{r reg1, echo = TRUE, eval = FALSE}
# Estimate regression
  e1 = lm(ProfLang ~ ProfMath, data = dcps)

# Visualize relationship
  scatter(ProfLang ~ ProfMath, data = dcps)
    abline(e1)

# Generate table of results
  stargazer(e1, type = 'text', keep.stat = 'n')
```


---
# Output

.pull-left[
```{r, fig.width=4, fig.height=4, dpi=200}
e1 = lm(ProfLang ~ ProfMath, data = dcps)
# Visualize
  plot(ProfLang ~ ProfMath, data = dcps, xlab = "Math", ylab = "Language", main = "Proficiency in DCPS")
  abline(e1)
```
]

.pull-right[
```{r, results ='asis'}
# Table of results
  stargazer(e1, type = 'html', style = 'apsr', digits = 2L, keep.stat = "n")
```
]

---
# Interpretation


.pull-left[

```{r, results='asis'}
# stargazer table
  stargazer::stargazer(est, type='html', digits = 2L, keep.stat='n')
```

]

.pull-right[

  Across DC public schools, expected language proficiency goes up by 0.94 points for every one-point increase in math proficiency.  
  The relationship is significant at the 5% level.
  
]

---
class: inverse, middle, right

# MULTIPLE REGRESSION
### Reducing bias

---
# Confunding bias

> Estimate = Estimand + Noise + Bias

- A confounder, $Z$, is a common cause of $X$ and $Y$

- Confounders induce bias, pulling the estimate away from the true estimand

- Mitigate bias with:
  - Control (e.g., experimental control)
  - Conditioning (e.g., multiple regression)



---
# Unconditional OLS

.pull-left[
- Unconditional model assumes:
$$
Y_i = \beta_0 + \beta_1 X_i + e_i
$$

- Assumes that the gray area is the *unique* correlation b/w $X$ and $Y$.
]

.pull-right[

```{r, engine='tikz', out.width='70%'}

	\def\firstcircle{(90:.75cm) circle (1cm)}
	\def\secondcircle{(210:.75cm) circle (1cm)}
	\def\thirdcircle{(330:.75cm) circle (1cm)}	
	
	\def\mono{(330:1.25cm) circle (.5cm)}	
	\def\exog{(25:1.25cm) circle (.75cm)}
	\def\mc{(250:.1cm) circle (1cm)}
	
	\begin{tikzpicture}
		\begin{scope}
			\begin{scope}[even odd rule]
				\clip \firstcircle;
				\fill[blue!80!white] \firstcircle;
			\end{scope}
			
			\begin{scope}[even odd rule]
				\clip \secondcircle;
				\fill[red!80!black] \secondcircle;
			\end{scope}
			
			\begin{scope}
				\clip \firstcircle;
				\clip \secondcircle;
				\fill[gray] \secondcircle;
			\end{scope}
      		
			\draw \firstcircle node[text=black,above] {$Y$};
			\draw \secondcircle node [text=black,below left] {$X$};
			\draw \thirdcircle node [text=black,below right] {$Z$};
    		\end{scope}
	\end{tikzpicture}

```

]

---
# Confounding bias in OLS


.pull-left[
- Assume $Y$ is a function of $X$ and $Z$:

$$
Y_i = \beta_0 + \beta_1 X_i + \beta_2 Z_i + e_i
$$

- But you ignore $Z$ and estimate:

$$
Y_i = \beta_0 + \beta^* _1 X_i + e_i
$$

- Then $\beta^* _1$ includes:
  - $\beta_1$: association b/w X and Y (magenta) 
  - **BIAS**: association b/w X and Z and Y (black)

]

.pull-right[

```{r, engine='tikz', out.width='70%'}

	\def\firstcircle{(90:.75cm) circle (1cm)}
	\def\secondcircle{(210:.75cm) circle (1cm)}
	\def\thirdcircle{(330:.75cm) circle (1cm)}	
	
	\def\mono{(330:1.25cm) circle (.5cm)}	
	\def\exog{(25:1.25cm) circle (.75cm)}
	\def\mc{(250:.1cm) circle (1cm)}
	
	
	\begin{tikzpicture}
		\begin{scope}
			\begin{scope}[even odd rule]
				\clip \thirdcircle (-2,-2) rectangle (2,2);
				\fill[blue!80!white] \firstcircle;
			\end{scope}
			
			\begin{scope}[even odd rule]
				\clip \firstcircle (-2,-2) rectangle (2,2);
				\fill[yellow] \thirdcircle;
			\end{scope}
			
			\begin{scope}[even odd rule]
				\clip \firstcircle (-2,-2) rectangle (2,2);
				\clip \secondcircle;
				\fill[red!80!black] \secondcircle;
			\end{scope}
			
			\begin{scope}
				\clip \firstcircle;
				\clip \thirdcircle;
				\fill[green!80!black] \thirdcircle;
			\end{scope}
			
			\begin{scope}
				\clip \secondcircle;
				\clip \thirdcircle;
				\fill[orange!80!black] \secondcircle;
			\end{scope}
			
			\begin{scope}
				\clip \firstcircle;
				\clip \secondcircle;
				\fill[magenta!80!black] \secondcircle;
			\end{scope}
			
			\begin{scope}
				\clip \firstcircle;
				\clip \secondcircle;
				\fill[black] \thirdcircle;
			\end{scope}   
			     		
			\draw \firstcircle node[text=black,above] {$Y$};
			\draw \secondcircle node [text=black,below left] {$X$};
			\draw \thirdcircle node [text=black,below right] {$Z$};
    		\end{scope}
	\end{tikzpicture}

```

]



---
# OLS and conditional effects

Worried that Z is a confounder? Add it to the model!

$$
Y_i = b_0 + b_1 X_i + b_2 Z_i + e_i
$$

Conditional slope coefficient, $b_1$
- Expected value of $Y$ increases/decreases by $b_1$ for unit-increase in $X$
- ...conditional on Z


---
# Implementation in R

.pull-left[

```{r mreg1,echo=TRUE,eval=FALSE}
# Unconditional estimate
  e1 = lm(ProfLang ~ ProfMath, data = dcps)

# Conditional estimate
  e2 = lm(ProfLang ~ ProfMath + NumTested, data = dcps)

# Generate table with both
  stargazer(e1, e2, type = 'text', keep.stat = 'n')
```
]

.pull-right[

```{r,results ='asis'}
e2 = lm(ProfLang ~ ProfMath + NumTested, data=dcps)
stargazer(e1,e2, type = 'html', style = 'apsr', keep.stat = 'n', digits = 2L, title = "Conditional estimates")
```

]

---
class: inverse, middle, right

# EC QUIZ
### Building on last week

---
# Where to start

- Set up a new R script (be sure to load `haven`)

- Open `anes2012 workshop.rdata`

- Filter for white, non-Hispanic respondents

- Use freq table and text to describe data on `global.warming`

- Use graph or table and text to describe `party.id`


---
# EC Quiz

> Evaluate relationship between attitudes about feminists (Y) and racial resentment (X) using linear regression. Present and interpret a single table with unconditional and conditional estimates.
>
> Submit your table and interpretation in a document (.docx or .pdf) on Canvas.


- Model 1: Unconditional relationship

- Model 2: Same but conditional on 
  - party identification 
  - political ideology
  - national economic evaluation
  - age
  
